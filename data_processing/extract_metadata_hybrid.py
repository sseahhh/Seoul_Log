"""
í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹±: 1ë‹¨ê³„ Gemini + 2ë‹¨ê³„ ìˆœìˆ˜ ì½”ë“œ

ì‚¬ìš©ë²•:
    python extract_metadata_hybrid.py

íŠ¹ì§•:
    - 1ë‹¨ê³„: Gemini 2.5 Proë¡œ ì „ì²´ txt ë¶„ì„ â†’ ì•ˆê±´ ë¼ì¸ ë§¤í•‘
    - 2ë‹¨ê³„: ìˆœìˆ˜ Python ì½”ë“œë¡œ ë°œì–¸ ì¶”ì¶œ (ë¹ ë¥´ê³  ì•ˆì •ì )
    - ë¹„ìš© ì ˆê°: Gemini 2.5 Flash ë‹¨ê³„ ì œê±°
    - ì†ë„ í–¥ìƒ: 10ë°° ì´ìƒ ë¹ ë¦„
    - ì•ˆì •ì„±: JSON íŒŒì‹± ì˜¤ë¥˜ ì—†ìŒ
"""

import requests
from bs4 import BeautifulSoup, NavigableString
import json
import os
import re
import logging
from datetime import datetime
from pathlib import Path
from google import genai
from google.genai import types
from typing import List, Dict, Optional

# ë¡œê·¸ ì„¤ì •
def setup_logging():
    """ë¡œê·¸ ì„¤ì •"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"parsing_hybrid_{timestamp}.log"

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

    # AFC (Automatic Function Calling) ë¡œê·¸ ìˆ¨ê¸°ê¸°
    logging.getLogger('google.genai').setLevel(logging.WARNING)
    logging.getLogger('google.ai.generativelanguage').setLevel(logging.WARNING)

    return logging.getLogger(__name__)

logger = setup_logging()


def extract_text_with_links(element):
    """HTML ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ì™€ ë§í¬ë¥¼ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ"""
    result = []

    for child in element.children:
        if isinstance(child, NavigableString):
            text = str(child)
            if text:
                result.append({"type": "text", "content": text})
        elif child.name == 'a':
            link_text = child.get_text()
            href = child.get('href', '')

            if href.startswith('/'):
                full_url = f"https://ms.smc.seoul.kr{href}"
            elif href.startswith('http'):
                full_url = href
            else:
                full_url = href

            result.append({"type": "link", "text": link_text, "url": full_url})
        elif child.name == 'br':
            result.append({"type": "text", "content": "\n"})
        elif child.name == 'hr':
            result.append({"type": "separator", "content": "---"})
        else:
            result.extend(extract_text_with_links(child))

    return result


def extract_reference_materials(content_list):
    """
    (ì°¸ê³ ) ì„¹ì…˜ì—ì„œ ì°¸ê³ ìë£Œ ë§í¬ ì¶”ì¶œ

    Returns:
        [{"title": "ë¬¸ì„œëª…", "url": "ë‹¤ìš´ë¡œë“œ URL"}]
    """
    attachments = []
    in_reference = False
    pending_links = []

    for i, item in enumerate(content_list):
        # (ì°¸ê³ ) ì‹œì‘ ê°ì§€
        if item.get("type") == "text" and "(ì°¸ê³ )" in item.get("content", ""):
            in_reference = True
            pending_links = []
            continue

        # (íšŒì˜ë¡ ëì— ì‹¤ìŒ) ê°ì§€ ì‹œ ì¢…ë£Œ
        if in_reference and item.get("type") == "text" and "íšŒì˜ë¡ ëì— ì‹¤ìŒ" in item.get("content", ""):
            in_reference = False
            # pending_linksë¥¼ attachmentsì— ì¶”ê°€
            attachments.extend(pending_links)
            pending_links = []
            continue

        # (ì°¸ê³ ) êµ¬ê°„ ë‚´ì˜ ë§í¬ ìˆ˜ì§‘
        if in_reference and item.get("type") == "link":
            # PDF/HWP ë‹¤ìš´ë¡œë“œ ë§í¬ë§Œ ì¶”ì¶œ
            url = item.get("url", "")
            if "appendixDownload" in url or url.endswith(('.pdf', '.hwp', '.docx')):
                pending_links.append({
                    "title": item.get("text", "").strip(),
                    "url": url
                })

    return attachments


def crawl_url(url: str) -> Dict:
    """URL í¬ë¡¤ë§í•˜ì—¬ txt í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    logger.info(f"í¬ë¡¤ë§ ì‹œì‘: {url}")
    print(f"ğŸŒ í¬ë¡¤ë§ ì‹œì‘: {url}\n")

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    response = requests.get(url, headers=headers, timeout=30)
    response.encoding = 'utf-8'

    if response.status_code != 200:
        raise Exception(f"HTTP {response.status_code}")

    soup = BeautifulSoup(response.text, 'html.parser')
    canvas = soup.find('div', id='canvas')

    if not canvas:
        raise Exception("ë©”ì¸ ì»¨í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    title = soup.title.string if soup.title else "ì œëª© ì—†ìŒ"
    title = title.strip()

    # í…ìŠ¤íŠ¸ + ë§í¬ ì¶”ì¶œ
    extracted = extract_text_with_links(canvas)

    # ì²¨ë¶€ ë¬¸ì„œ ì¶”ì¶œ (ì°¸ê³  ì„¹ì…˜ì—ì„œ)
    attachments = extract_reference_materials(extracted)

    # txt ë³€í™˜
    lines = []
    for item in extracted:
        if item['type'] == 'text':
            text = item['content'].strip()
            if text:
                lines.append(text)
        elif item['type'] == 'separator':
            lines.append('---')

    txt_content = '\n'.join(lines)

    # ì°¸ê³ ìë£Œ ì œê±°
    if '(íšŒì˜ë¡ ëì— ì‹¤ìŒ)' in txt_content:
        txt_content = txt_content.split('(íšŒì˜ë¡ ëì— ì‹¤ìŒ)')[0]
    if '(ì°¸ê³ )' in txt_content:
        txt_content = txt_content.split('(ì°¸ê³ )')[0]

    logger.info(f"í¬ë¡¤ë§ ì™„ë£Œ: {len(txt_content)} bytes, ì²¨ë¶€ {len(attachments)}ê°œ")
    print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(txt_content):,} bytes\n")
    print(f"ğŸ“ ì²¨ë¶€ ë¬¸ì„œ: {len(attachments)}ê°œ\n")

    return {
        "title": title,
        "url": url,
        "content": txt_content,
        "attachments": attachments
    }


def extract_agenda_mapping(
    txt_content: str,
    title: str,
    url: str,
    api_key: str,
    attachments: List[Dict] = None,
    model: str = "gemini-2.5-pro",
    max_retries: int = 3
) -> Dict:
    """
    1ë‹¨ê³„: Geminië¡œ ì•ˆê±´ ë¼ì¸ ë§¤í•‘ ì¶”ì¶œ

    Args:
        txt_content: íšŒì˜ë¡ í…ìŠ¤íŠ¸
        title: íšŒì˜ë¡ ì œëª©
        url: íšŒì˜ë¡ URL
        api_key: Google API Key
        attachments: ì²¨ë¶€ ë¬¸ì„œ ëª©ë¡ [{"title": "...", "url": "..."}]
        model: ì‚¬ìš©í•  ëª¨ë¸
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸: 3)

    Returns:
        {
            "meeting_info": {
                "title": "...",
                "url": "...",
                "date": "YYYY.MM.DD"
            },
            "agenda_mapping": [
                {
                    "agenda_title": "ì•ˆê±´ ì œëª©",
                    "line_start": 1,
                    "line_end": 50,
                    "speakers": ["ë°œì–¸ì1", "ë°œì–¸ì2"],
                    "attachments": [{"title": "...", "url": "..."}]
                },
                ...
            ]
        }
    """
    logger.info("1ë‹¨ê³„: ì•ˆê±´ ë¼ì¸ ë§¤í•‘ ì¶”ì¶œ ì‹œì‘")
    print("=" * 80)
    print("1ë‹¨ê³„: ì•ˆê±´ ë¼ì¸ ë§¤í•‘ ì¶”ì¶œ (Gemini 2.5 Pro)")
    print("=" * 80)
    print()

    # ì¬ì‹œë„ ë¡œì§
    for attempt in range(1, max_retries + 1):
        try:
            if attempt > 1:
                print(f"ğŸ”„ ì¬ì‹œë„ {attempt}/{max_retries}...")
                logger.info(f"ì¬ì‹œë„ {attempt}/{max_retries}")

            result, tokens = _extract_agenda_mapping_once(
                txt_content, title, url, api_key, attachments, model
            )
            return result, tokens

        except json.JSONDecodeError as e:
            if attempt < max_retries:
                print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt}/{max_retries}): {e}")
                print(f"   ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt}/{max_retries}): {e}")
                continue
            else:
                print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ({max_retries}íšŒ) ë„ë‹¬, ì‹¤íŒ¨")
                logger.error(f"ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬: {e}")
                raise
        except Exception as e:
            # JSON íŒŒì‹± ì™¸ ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ì—†ì´ ë°”ë¡œ raise
            raise


def _extract_agenda_mapping_once(
    txt_content: str,
    title: str,
    url: str,
    api_key: str,
    attachments: List[Dict] = None,
    model: str = "gemini-2.5-pro"
) -> Dict:
    """
    1ë‹¨ê³„: Geminië¡œ ì•ˆê±´ ë¼ì¸ ë§¤í•‘ ì¶”ì¶œ (ë‹¨ì¼ ì‹œë„)

    ì¬ì‹œë„ ë¡œì§ ì—†ì´ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
    """

    client = genai.Client(api_key=api_key)

    # ë¼ì¸ ë²ˆí˜¸ ì¶”ê°€
    lines = txt_content.split('\n')
    numbered_text = ""
    for i, line in enumerate(lines, 1):
        numbered_text += f"{i:4d} | {line}\n"

    # ì²¨ë¶€ ë¬¸ì„œ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Geminiì—ê²Œ ì „ë‹¬)
    attachments_text = ""
    if attachments:
        attachments_text = "\n\nì²¨ë¶€ ë¬¸ì„œ ëª©ë¡:\n"
        for idx, att in enumerate(attachments, 1):
            attachments_text += f"{idx}. {att['title']} (URL: {att['url']})\n"

    prompt = f"""ë‹¤ìŒì€ ì„œìš¸ì‹œì˜íšŒ íšŒì˜ë¡ì…ë‹ˆë‹¤. ì´ íšŒì˜ë¡ì„ ë¶„ì„í•˜ì—¬ ì•ˆê±´ë³„ ë¼ì¸ ë²ˆí˜¸ ë§¤í•‘ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

íšŒì˜ë¡ ì œëª©: {title}
íšŒì˜ë¡ URL: {url}
{attachments_text}

íšŒì˜ë¡ ë‚´ìš© (ë¼ì¸ ë²ˆí˜¸ í¬í•¨):
{numbered_text}

ì‘ì—…:
1. meeting_info ì¶”ì¶œ:
   - meeting_url: ìœ„ì— ì œê³µëœ "íšŒì˜ë¡ URL"ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
   - date: ì œëª©ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (YYYY.MM.DD í˜•ì‹)

2. agenda_mapping ì¶”ì¶œ:

**ì•ˆê±´ ì‹ë³„ ê·œì¹™:**

1ë‹¨ê³„: "ì‹¬ì‚¬ëœì•ˆê±´" ë˜ëŠ” "ì˜ì‚¬ì¼ì •" ì„¹ì…˜ì—ì„œ ì•ˆê±´ ëª©ë¡ ì¶”ì¶œ
   - "1. 2. 3. ..." í˜•íƒœì˜ ì•ˆê±´ ëª©ë¡ì„ ëª¨ë‘ ì°¾ìœ¼ì„¸ìš”
   - agenda_titleì€ ë²ˆí˜¸ë¥¼ ì œì™¸í•œ ìˆœìˆ˜ ì•ˆê±´ëª…ë§Œ ì‚¬ìš©
   - ì˜ˆ: "1. ê¸°íšì¡°ì •ì‹¤ í˜„ì•ˆ ì—…ë¬´ë³´ê³ " â†’ "ê¸°íšì¡°ì •ì‹¤ í˜„ì•ˆ ì—…ë¬´ë³´ê³ "

2ë‹¨ê³„: ê° ì•ˆê±´ì˜ ë…¼ì˜ êµ¬ê°„ ì§€ì • (ì¼ê´„ìƒì • ì•ˆê±´ ì²˜ë¦¬ ê·œì¹™)
   - "---" êµ¬ë¶„ì„ , "â—‹ìœ„ì›ì¥" ë˜ëŠ” "â—‹ì˜ì¥" ë°œì–¸, ì•ˆê±´ëª… ì–¸ê¸‰ì„ ì°¸ê³ í•˜ì—¬ line_start, line_end ì§€ì •

   **ë³¸íšŒì˜ ì¼ê´„ìƒì • ì•ˆê±´ ì²˜ë¦¬:**
   - íšŒì˜ ì œëª©ì— "ë³¸íšŒì˜"ê°€ í¬í•¨ë˜ê³  ì—¬ëŸ¬ ì•ˆê±´ì´ ì¼ê´„ ìƒì •ëœ ê²½ìš°
   - ê° ì•ˆê±´ë³„ë¡œ "ì˜ì‚¬ì¼ì • ì œXí•­ì€ ê°€ê²°ë˜ì—ˆìŒ" ë˜ëŠ” "ì˜ì‚¬ì¼ì • ì œXí•­ì„ í‘œê²°í•˜ê² ìŠµë‹ˆë‹¤" í˜•íƒœì˜ ê°œë³„ í‘œê²°ì´ ìˆëŠ”ì§€ í™•ì¸
   - ê°œë³„ í‘œê²°ì´ ìˆìœ¼ë©´ â†’ **ê° ì•ˆê±´ì„ ë°˜ë“œì‹œ ë¶„ë¦¬**
     * ê° ì•ˆê±´ì˜ line_start: í•´ë‹¹ ì•ˆê±´ í‘œê²° ì‹œì‘ ë¼ì¸ (ì˜ˆ: "ì˜ì‚¬ì¼ì • ì œ24í•­ ... í‘œê²°í•˜ê² ìŠµë‹ˆë‹¤")
     * ê° ì•ˆê±´ì˜ line_end: í•´ë‹¹ ì•ˆê±´ í‘œê²° ì¢…ë£Œ ë¼ì¸ (ì˜ˆ: "ê°€ê²°ë˜ì—ˆìŒì„ ì„ í¬í•©ë‹ˆë‹¤" ë˜ëŠ” ë‹¤ìŒ ì•ˆê±´ ì‹œì‘ ì§ì „)
     * ê° ì•ˆê±´ì˜ status: ê°œë³„ í‘œê²° ê²°ê³¼ ë°˜ì˜

   **ìœ„ì›íšŒ ì¼ê´„ìƒì • ì•ˆê±´ ì²˜ë¦¬ (ë³¸íšŒì˜ ì™¸):**
   - ì—¬ëŸ¬ ì•ˆê±´ì´ "ì¼ê´„ ìƒì •" ë˜ëŠ” "ì¼ê´„í•´ì„œ ìƒì •"ëœ ê²½ìš° ë³¸ë¬¸ì„ ë¶„ì„í•˜ì—¬ íŒë‹¨:

   ì¡°ê±´ A (í†µí•© ì²˜ë¦¬): ë‹¤ìŒ ì¡°ê±´ì„ **ëª¨ë‘** ë§Œì¡±í•˜ë©´ í†µí•©
     âœ“ ì¼ê´„ ì œì•ˆì„¤ëª… (ê° ì•ˆê±´ë³„ ê°œë³„ ì„¤ëª… ì—†ìŒ)
     âœ“ ì¼ê´„ ê²€í† ë³´ê³  (ê° ì•ˆê±´ë³„ ê°œë³„ ê²€í†  ì—†ìŒ)
     âœ“ ì¼ê´„ ì§ˆì˜ì‘ë‹µ (ì•ˆê±´ êµ¬ë¶„ ì—†ì´ ì „ì²´ì— ëŒ€í•œ ì§ˆì˜)
     âœ“ ì¼ê´„ í‘œê²° (ê° ì•ˆê±´ë³„ ê°œë³„ í‘œê²° ì—†ìŒ)
     â†’ agenda_titleì„ ì‰¼í‘œë¡œ ì—°ê²°: "ì•ˆê±´1,ì•ˆê±´2,ì•ˆê±´3,ì•ˆê±´4"
     â†’ line_start/line_endëŠ” ì „ì²´ ë…¼ì˜ êµ¬ê°„ í•˜ë‚˜ë¡œ ì§€ì •
     â†’ statusëŠ” ì „ì²´ ì•ˆê±´ì˜ ê³µí†µ ì²˜ë¦¬ ê²°ê³¼

   ì¡°ê±´ B (ë¶„ë¦¬ ì²˜ë¦¬): ë‹¤ìŒ ì¡°ê±´ ì¤‘ **í•˜ë‚˜ë¼ë„** í•´ë‹¹í•˜ë©´ ë¶„ë¦¬
     âœ“ ê° ì•ˆê±´ë³„ë¡œ ê°œë³„ ì œì•ˆì„¤ëª…ì´ êµ¬ë¶„ë˜ì–´ ìˆìŒ
     âœ“ ê° ì•ˆê±´ë³„ë¡œ ê°œë³„ ê²€í† ë³´ê³ ê°€ êµ¬ë¶„ë˜ì–´ ìˆìŒ
     âœ“ ê° ì•ˆê±´ì— ëŒ€í•œ ê°œë³„ ì§ˆì˜ì‘ë‹µì´ "---" êµ¬ë¶„ì„ ìœ¼ë¡œ ë‚˜ë‰˜ì–´ ìˆìŒ
     âœ“ ê° ì•ˆê±´ë³„ë¡œ ê°œë³„ í‘œê²°ì´ ì§„í–‰ë¨
     â†’ ê° ì•ˆê±´ì„ ë³„ë„ agendaë¡œ ë¶„ë¦¬
     â†’ ê°ê°ì˜ line_start/line_end ê°œë³„ ì§€ì •
     â†’ ê°ê°ì˜ status ê°œë³„ ê¸°ë¡

   **íŒë‹¨ ì˜ˆì‹œ:**
   ì˜ˆì‹œ 1 (í†µí•©): "ì˜ì‚¬ì¼ì • ì œ4í•­~ì œ8í•­ì„ ì¼ê´„ ìƒì •" â†’ ìœ„ì›ì¥ì´ 5ê°œ ì•ˆê±´ì„ í•œë²ˆì— ì„¤ëª… â†’ ì „ë¬¸ìœ„ì›ì´ ì¼ê´„ ê²€í† ë³´ê³  â†’ ì§ˆì˜ì‘ë‹µ â†’ "ì œ4í•­ë¶€í„° ì œ8í•­ê¹Œì§€ ì›ì•ˆëŒ€ë¡œ ì˜ê²°" (í•œë²ˆì— í‘œê²°)
   â†’ agenda_title: "ì•ˆê±´4,ì•ˆê±´5,ì•ˆê±´6,ì•ˆê±´7,ì•ˆê±´8"

   ì˜ˆì‹œ 2 (ë¶„ë¦¬): "ì˜ì‚¬ì¼ì • ì œ24í•­~ì œ33í•­ì„ ì¼ê´„ ìƒì •" â†’ ì‹¬ì‚¬ë³´ê³ ëŠ” ìƒëµ â†’ í•˜ì§€ë§Œ "ì œ24í•­ì„ í‘œê²°í•˜ê² ìŠµë‹ˆë‹¤" â†’ "ì œ25í•­ì„ í‘œê²°í•˜ê² ìŠµë‹ˆë‹¤" â†’ ... (ê°ê° ê°œë³„ íˆ¬í‘œ)
   â†’ 10ê°œì˜ ê°œë³„ agendaë¡œ ë¶„ë¦¬

**íšŒì˜ë¡ êµ¬ì¡° ì´í•´:**
- íšŒì˜ë¡ì€ "---" êµ¬ë¶„ì„ ìœ¼ë¡œ ì„¹ì…˜ì´ ë‚˜ë‰˜ì–´ì ¸ ìˆìŒ
- ê° "---" êµ¬ë¶„ì„  ì‚¬ì´ì— ì‹¤ì œ ë°œì–¸("â—‹ìœ„ì›ì¥", "â—‹ìœ„ì›" ë“±)ì´ í¬í•¨ëœ êµ¬ê°„ì€ í•˜ë‚˜ì˜ ì•ˆê±´ìœ¼ë¡œ ì¶”ì¶œ
- ì²¨ë¶€ ë¬¸ì„œ(download_url)ëŠ” í•´ë‹¹ ì•ˆê±´ ë…¼ì˜ ì§í›„ì— "(ì°¸ê³ )" í˜•íƒœë¡œ ì œê³µë˜ë©°, ë°”ë¡œ ì• ì•ˆê±´ì˜ attachmentsì— ë§¤í•‘
- line_startëŠ” ì‹¤ì œ ë°œì–¸ì´ ì‹œì‘ë˜ëŠ” ì²« ë¼ì¸, line_endëŠ” ë°œì–¸ì´ ëë‚˜ëŠ” ë§ˆì§€ë§‰ ë¼ì¸ ("---" êµ¬ë¶„ì„ ì´ë‚˜ "(ì°¸ê³ )" ì„¹ì…˜ ì§ì „)

**ì•ˆê±´ ì™¸ ì„¹ì…˜:**
- ì•ˆê±´ ëª©ë¡ì— ì—†ì–´ë„ ì‹¤ì œ íšŒì˜ ë‚´ìš©(ê°œì˜, ì§ˆì˜ì‘ë‹µ, 5ë¶„ììœ ë°œì–¸, ì‚°íšŒ ë“±)ì€ ëª¨ë‘ í¬í•¨
- ì„¹ì…˜ ì„±ê²©ì— ë§ëŠ” ì ì ˆí•œ ì œëª© ì‚¬ìš©

**ì²¨ë¶€ ë¬¸ì„œ ë§¤ì¹­:**
- íšŒì˜ë¡ ë³¸ë¬¸ì—ì„œ ë§ˆí¬ë‹¤ìš´ ë§í¬ í˜•ì‹ì˜ ì²¨ë¶€ ë¬¸ì„œë¥¼ ì°¾ì•„ì„œ ë§¤ì¹­
  * í˜•ì‹: [ë¬¸ì„œëª…](https://ms.smc.seoul.kr/record/appendixDownload.do?key=...)
  * (ì°¸ê³ ) ì„¹ì…˜ì˜ ë§í¬ëŠ” ë°”ë¡œ ì§ì „ ì•ˆê±´ì— ì†í•¨
- ê° ì•ˆê±´ì— í•´ë‹¹í•˜ëŠ” ì²¨ë¶€ ë¬¸ì„œë¥¼ attachments í•„ë“œì— ë°°ì—´ë¡œ ì¶”ê°€
- ì•ˆê±´ê³¼ ê´€ë ¨ ì—†ëŠ” ì²¨ë¶€ ë¬¸ì„œëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
- ì²¨ë¶€ ë¬¸ì„œê°€ ì—†ëŠ” ì•ˆê±´ì€ attachmentsë¥¼ ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •
- **ì¤‘ìš”**: URLì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ê³ , URLì´ ì—†ìœ¼ë©´ nullë¡œ ì„¤ì •í•˜ì§€ ë§ê³  í•´ë‹¹ í•­ëª©ì„ ì œì™¸

**ì¤‘ìš”:**
- ëª¨ë“  ì•ˆê±´ì„ ë¹ ì§ì—†ì´ í¬í•¨ (ë‹¨ í•˜ë‚˜ë„ ëˆ„ë½ ê¸ˆì§€)
- "(íšŒì˜ë¡ ëì— ì‹¤ìŒ)" ë˜ëŠ” "(ì°¸ê³ )" ì„¹ì…˜ì€ ì œì™¸
- speakers: í•´ë‹¹ êµ¬ê°„ì˜ ë°œì–¸ì ëª©ë¡ (â—‹ ë‹¤ìŒ ì´ë¦„, ë°œì–¸ ìˆœì„œëŒ€ë¡œ)

**ì•ˆê±´ íƒ€ì… ë¶„ë¥˜:**
ê° ì•ˆê±´ì— agenda_type í•„ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜:
- "legislation": ì¡°ë¡€ì•ˆ, ê·œì¹™ì•ˆ ë“± ì…ë²• ì•ˆê±´
- "report": ì—…ë¬´ë³´ê³ , í˜„ì•ˆë³´ê³  ë“± ë³´ê³  ì•ˆê±´
- "budget": ì˜ˆì‚°ì•ˆ, ê²°ì‚° ê´€ë ¨ ì•ˆê±´
- "consent": ë™ì˜ì•ˆ, ìŠ¹ì¸ì•ˆ, ì˜ê²¬ì²­ì·¨ ì•ˆê±´
- "procedural": ê°œì˜, ê°œíšŒ, ííšŒ, ì‚°íšŒ ë“± ì ˆì°¨ì  ì•ˆê±´
- "personnel": ìœ„ì›ì¥ ì„ ê±°, ìœ„ì› ì„ ì„ ë“± ì¸ì‚¬ ì•ˆê±´
- "discussion": ì§ˆì˜ì‘ë‹µ, 5ë¶„ììœ ë°œì–¸ ë“± í† ë¡ 
- "other": ê¸°íƒ€

**ì•ˆê±´ ìƒíƒœ ì¶”ì¶œ:**
ê° ì•ˆê±´ì˜ ì²˜ë¦¬ ìƒíƒœë¥¼ íŒŒì•…í•˜ì—¬ status í•„ë“œì— ê¸°ë¡:
- íšŒì˜ë¡ì—ì„œ í•´ë‹¹ ì•ˆê±´ì´ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ ì°¾ì•„ì„œ ê¸°ë¡
- ê°€ëŠ¥í•œ ìƒíƒœ ê°’:
  * "ì›ì•ˆê°€ê²°": "ì›ì•ˆê°€ê²°", "ê°€ê²°ë˜ì—ˆìŒ", "ì˜ê²°ë˜ì—ˆìŒ" ë“±
  * "ìˆ˜ì •ê°€ê²°": "ìˆ˜ì •ê°€ê²°", "ì¼ë¶€ ìˆ˜ì •í•˜ì—¬ ê°€ê²°" ë“±
  * "ë¶€ê²°": "ë¶€ê²°ë˜ì—ˆìŒ"
  * "ë³¸íšŒì˜ ìƒì •": "ë³¸íšŒì˜ì— ë¶€ì˜", "ë³¸íšŒì˜ ìƒì •" ë“±
  * "ìœ„ì›íšŒ ì‹¬ì‚¬ì¤‘": "ìœ„ì›íšŒì— ìƒì •", "ì‹¬ì‚¬ ì¤‘" ë“±
  * "ì ‘ìˆ˜": ìƒíƒœê°€ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’
- íšŒì˜ë¡ì— ëª…ì‹œëœ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì˜ˆ: "ì›ì•ˆê°€ê²°ë˜ì—ˆìŒì„ ì„ í¬í•©ë‹ˆë‹¤" â†’ "ì›ì•ˆê°€ê²°")
- ìƒíƒœê°€ ë¶ˆëª…í™•í•˜ë©´ "ì ‘ìˆ˜" ì‚¬ìš©

JSON ì¶œë ¥ í˜•ì‹:
{{{{
  "meeting_info": {{{{
    "title": "{title}",
    "meeting_url": "{url}",
    "date": "YYYY.MM.DD"
  }}}},
  "agenda_mapping": [
    {{{{
      "agenda_title": "ì•ˆê±´ëª…",
      "agenda_type": "legislation",
      "status": "ì›ì•ˆê°€ê²°",
      "line_start": 1,
      "line_end": 50,
      "speakers": ["ë°œì–¸ì1", "ë°œì–¸ì2"],
      "attachments": [
        {{{{"title": "ë¬¸ì„œëª…", "download_url": "ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ URL"}}}}
      ]
    }}}}
  ]
}}}}

ê·œì¹™:
- ìˆœìˆ˜ JSONë§Œ ì¶œë ¥
- agenda_mappingì€ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë°°ì—´
- line_start, line_endëŠ” ì‹¤ì œ ë¼ì¸ ë²ˆí˜¸ ì‚¬ìš©
- attachmentsëŠ” í•´ë‹¹ ì•ˆê±´ì— ì†í•œ ì²¨ë¶€ ë¬¸ì„œë§Œ í¬í•¨ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)
- agenda_typeì€ ë°˜ë“œì‹œ ìœ„ 8ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜
- statusëŠ” íšŒì˜ë¡ì—ì„œ ì¶”ì¶œí•œ ì‹¤ì œ ì²˜ë¦¬ ìƒíƒœ (ì—†ìœ¼ë©´ "ì ‘ìˆ˜")
"""

    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.1,
                response_mime_type="application/json",
            )
        )
    except Exception as e:
        error_msg = f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}"
        print(f"âŒ {error_msg}")
        logger.error(error_msg)
        import traceback
        traceback.print_exc()
        raise

    # finish_reason í™•ì¸ (ë””ë²„ê¹…)
    if response.candidates and len(response.candidates) > 0:
        finish_reason = getattr(response.candidates[0], 'finish_reason', None)
        if finish_reason:
            print(f"ğŸ” Finish Reason: {finish_reason}")
            if finish_reason not in ['STOP', 1]:  # STOP = ì •ìƒ ì™„ë£Œ
                print(f"âš ï¸  ì‘ë‹µì´ ë¹„ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë¨: {finish_reason}")

    response_text = None
    try:
        response_text = response.text
    except Exception as e:
        print(f"âŒ response.text ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        logger.error(f"response.text ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    if not response_text:
        print("âš ï¸  response.textê°€ ë¹„ì–´ìˆìŒ, candidatesì—ì„œ ì¶”ì¶œ ì‹œë„...")
        if response.candidates and len(response.candidates) > 0:
            candidate = response.candidates[0]
            if hasattr(candidate, 'content') and candidate.content:
                if hasattr(candidate.content, 'parts') and candidate.content.parts:
                    if len(candidate.content.parts) > 0:
                        part = candidate.content.parts[0]
                        if hasattr(part, 'text'):
                            response_text = part.text
                            print(f"âœ… candidatesì—ì„œ ì¶”ì¶œ ì„±ê³µ (ê¸¸ì´: {len(response_text)})")

    if not response_text:
        error_msg = "Gemini ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
        print(f"âŒ {error_msg}")
        print(f"   Response: {response}")
        if hasattr(response, 'prompt_feedback'):
            print(f"   Prompt Feedback: {response.prompt_feedback}")
        logger.error(error_msg)
        raise Exception(error_msg)

    try:
        result = json.loads(response_text)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì—ëŸ¬: {e}")
        print(f"   Response text (ì²˜ìŒ 500ì): {response_text[:500]}")

        # ì „ì²´ ì‘ë‹µì„ íŒŒì¼ë¡œ ì €ì¥
        error_log_dir = Path("logs/gemini_errors")
        error_log_dir.mkdir(parents=True, exist_ok=True)
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        error_file = error_log_dir / f"json_error_{timestamp}.txt"
        with open(error_file, 'w', encoding='utf-8') as f:
            f.write(f"=== JSON íŒŒì‹± ì—ëŸ¬ ===\n")
            f.write(f"íšŒì˜ë¡: {title}\n")
            f.write(f"URL: {url}\n")
            f.write(f"ì—ëŸ¬: {e}\n")
            f.write(f"ëª¨ë¸: {model}\n")
            f.write(f"\n=== Gemini ì‘ë‹µ ì „ë¬¸ ===\n")
            f.write(response_text)
        print(f"   ì „ì²´ ì‘ë‹µ ì €ì¥: {error_file}")

        logger.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
        raise

    # í† í° ì •ë³´
    tokens = {"input": 0, "output": 0}
    if hasattr(response, 'usage_metadata'):
        tokens["input"] = getattr(response.usage_metadata, 'prompt_token_count', 0)
        tokens["output"] = getattr(response.usage_metadata, 'candidates_token_count', 0)

    logger.info(f"1ë‹¨ê³„ ì™„ë£Œ: {len(result['agenda_mapping'])}ê°œ ì•ˆê±´, í† í°={tokens['input']}+{tokens['output']}")
    print(f"âœ… ì•ˆê±´ ë§¤í•‘ ì¶”ì¶œ ì™„ë£Œ: {len(result['agenda_mapping'])}ê°œ")
    print(f"ğŸ“Š í† í°: input={tokens['input']:,}, output={tokens['output']:,}")
    print()

    return result, tokens


def parse_speaker_line(line: str) -> tuple:
    """
    ë°œì–¸ì ë¼ì¸ íŒŒì‹±

    ì˜ˆ: "â—‹ì˜ì¥ ìµœí˜¸ì •  ì•ˆë…•í•˜ì„¸ìš”." â†’ ("ì˜ì¥ ìµœí˜¸ì •", "ì•ˆë…•í•˜ì„¸ìš”.")
    ì˜ˆ: "â—‹ìœ„ì›ì¥ [ì„œìƒì—´](url)  ì•ˆë…•í•˜ì„¸ìš”." â†’ ("ìœ„ì›ì¥ ì„œìƒì—´", "ì•ˆë…•í•˜ì„¸ìš”.")
    """
    # ë§ˆí¬ë‹¤ìš´ ë§í¬ ì œê±° í•¨ìˆ˜
    def remove_markdown_links(text: str) -> str:
        # [í…ìŠ¤íŠ¸](url) â†’ í…ìŠ¤íŠ¸
        return re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)

    # â—‹ ë‹¤ìŒ ê³µë°± ì œê±°í•˜ê³  íŒŒì‹±
    match = re.match(r'^â—‹\s*(.+?)\s{2,}(.+)$', line)
    if match:
        speaker = remove_markdown_links(match.group(1).strip())
        text = match.group(2).strip()
        return speaker, text

    # ë°œì–¸ìë§Œ ìˆëŠ” ê²½ìš° (ë‹¤ìŒ ì¤„ë¶€í„° ë‚´ìš©)
    match = re.match(r'^â—‹\s*(.+)$', line)
    if match:
        speaker = remove_markdown_links(match.group(1).strip())
        return speaker, ""

    return None, None


def split_long_text(text: str, max_length: int = 500) -> List[str]:
    """
    ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 

    Args:
        text: ë¶„í• í•  í…ìŠ¤íŠ¸
        max_length: ìµœëŒ€ ê¸¸ì´

    Returns:
        ë¶„í• ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    if len(text) <= max_length:
        return [text]

    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    sentences = re.split(r'([.?!])\s+', text)

    chunks = []
    current_chunk = ""

    for i in range(0, len(sentences), 2):
        sentence = sentences[i]
        if i + 1 < len(sentences):
            sentence += sentences[i + 1]  # ë§ˆì¹¨í‘œ ì¶”ê°€

        if len(current_chunk) + len(sentence) > max_length:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence
        else:
            current_chunk += " " + sentence

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks if chunks else [text]


def parse_section_pure(section_text: str, agenda_title: str, speakers: List[str], previous_speaker: str = None) -> List[Dict]:
    """
    ìˆœìˆ˜ ì½”ë“œë¡œ ì„¹ì…˜ íŒŒì‹±

    Args:
        section_text: íšŒì˜ë¡ í…ìŠ¤íŠ¸
        agenda_title: ì•ˆê±´ëª…
        speakers: ë°œì–¸ì ëª©ë¡ (1ë‹¨ê³„ì—ì„œ ì œê³µ)
        previous_speaker: ì´ì „ êµ¬ê°„ì˜ ë§ˆì§€ë§‰ ë°œì–¸ì (ë°œì–¸ì ì—†ì„ ë•Œ ì‚¬ìš©)

    Returns:
        chunks ë¦¬ìŠ¤íŠ¸
    """
    chunks = []
    lines = section_text.split('\n')

    current_speaker = previous_speaker  # ì´ì „ ë°œì–¸ìë¡œ ì´ˆê¸°í™”
    current_text_lines = []

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # êµ¬ì¡°ì  ìš”ì†Œ í•„í„°ë§
        if line.startswith('---'):
            continue
        if '(ì°¸ê³ )' in line:
            continue
        if '(íšŒì˜ë¡ ëì— ì‹¤ìŒ)' in line:
            continue
        # ì•ˆê±´ ë²ˆí˜¸ ë¼ì¸ í•„í„°ë§ (ì˜ˆ: "1. ì•ˆê±´ëª… [](url)" í˜•íƒœ)
        if re.match(r'^\d+\.\s+.+\[\]\(https?://', line):
            continue
        # ì‹œê°„ í‘œê¸° í•„í„°ë§ (ì˜ˆ: (16ì‹  22ë¶„), (11ì‹œ 23ë¶„), (14ì‹œ 16ë¶„))
        if re.match(r'^\([0-9]{1,2}[ì‹œì‹ ]\s*[0-9]{0,2}\s*ë¶„?\)$', line.strip()):
            continue

        # â—‹ë¡œ ì‹œì‘í•˜ëŠ” ë°œì–¸ì ë¼ì¸ì¸ì§€ í™•ì¸
        if line.startswith('â—‹'):
            # ì´ì „ ë°œì–¸ ì €ì¥
            if current_speaker and current_text_lines:
                full_text = ' '.join(current_text_lines).strip()

                # 500ì ë„˜ìœ¼ë©´ ë¶„í• 
                text_chunks = split_long_text(full_text, max_length=500)

                for text_chunk in text_chunks:
                    chunks.append({
                        "speaker": current_speaker,
                        "agenda": agenda_title,
                        "text": text_chunk
                    })

            # ìƒˆ ë°œì–¸ì ì‹œì‘
            speaker, first_text = parse_speaker_line(line)

            if speaker:
                current_speaker = speaker
                current_text_lines = [first_text] if first_text else []
        else:
            # ë°œì–¸ ë‚´ìš© ê³„ì†
            if current_speaker:
                current_text_lines.append(line)

    # ë§ˆì§€ë§‰ ë°œì–¸ ì €ì¥
    if current_speaker and current_text_lines:
        full_text = ' '.join(current_text_lines).strip()
        text_chunks = split_long_text(full_text, max_length=500)

        for text_chunk in text_chunks:
            chunks.append({
                "speaker": current_speaker,
                "agenda": agenda_title,
                "text": text_chunk
            })

    return chunks


def parse_with_pure_code(txt_content: str, agenda_mapping: List[Dict]) -> List[Dict]:
    """
    2ë‹¨ê³„: ìˆœìˆ˜ ì½”ë“œë¡œ ë°œì–¸ ì¶”ì¶œ

    Args:
        txt_content: íšŒì˜ë¡ ë³¸ë¬¸ (í—¤ë” ì´ë¯¸ ì œê±°ë¨)
        agenda_mapping: 1ë‹¨ê³„ ê²°ê³¼ (ì•ˆê±´ ë§¤í•‘)

    Returns:
        ëª¨ë“  chunks
    """
    logger.info("2ë‹¨ê³„: ìˆœìˆ˜ ì½”ë“œë¡œ ë°œì–¸ ì¶”ì¶œ ì‹œì‘")
    print("=" * 80)
    print("2ë‹¨ê³„: ìˆœìˆ˜ ì½”ë“œë¡œ ë°œì–¸ ì¶”ì¶œ")
    print("=" * 80)
    print()

    # txt_contentëŠ” ì´ë¯¸ í—¤ë”ê°€ ì œê±°ëœ ìƒíƒœë¡œ ì „ë‹¬ë¨
    lines = txt_content.split('\n')

    all_chunks = []
    last_speaker = None  # ì´ì „ ë°œì–¸ì ì¶”ì 

    for idx, agenda in enumerate(agenda_mapping, 1):
        agenda_title = agenda['agenda_title']
        line_start = agenda['line_start'] - 1  # 0-indexed
        line_end = agenda['line_end']
        speakers = agenda.get('speakers', [])

        # ë¼ì¸ ë²”ìœ„ ì¶”ì¶œ
        section_lines = lines[line_start:line_end]
        section_text = '\n'.join(section_lines)

        # íŒŒì‹± (ì´ì „ ë°œì–¸ì ì „ë‹¬)
        chunks = parse_section_pure(section_text, agenda_title, speakers, last_speaker)

        # ì²­í¬ê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ë°œì–¸ì ì—…ë°ì´íŠ¸
        if chunks:
            last_speaker = chunks[-1]['speaker']

        msg = f"[{idx}/{len(agenda_mapping)}] {len(chunks)}ê°œ ë°œì–¸ ì¶”ì¶œ: {agenda_title[:50]}..."
        logger.info(msg)
        print(f"  âœ“ {msg}")

        all_chunks.extend(chunks)

    logger.info(f"2ë‹¨ê³„ ì™„ë£Œ: ì´ {len(all_chunks)}ê°œ ë°œì–¸ ì¶”ì¶œ")
    print()
    print(f"âœ… ì´ {len(all_chunks)}ê°œ ë°œì–¸ ì¶”ì¶œ ì™„ë£Œ!")
    print()

    return all_chunks


def extract_metadata_from_url(
    url: str,
    api_key: str,
    stage1_model: str = "gemini-2.5-pro",
    verbose: bool = True
) -> Dict:
    """
    URLì—ì„œ ì§ì ‘ í¬ë¡¤ë§ + í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± (ì²¨ë¶€ ë¬¸ì„œ í¬í•¨)

    Args:
        url: íšŒì˜ë¡ URL
        api_key: Google API Key
        stage1_model: 1ë‹¨ê³„ ëª¨ë¸ (ê¸°ë³¸: gemini-2.5-pro)
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸: True)

    Returns:
        {
            "meeting_info": {...},
            "chunks": [...],
            "usage": {...}
        }
    """
    logger.info(f"URL ê¸°ë°˜ íŒŒì‹± ì‹œì‘: {url}")

    if verbose:
        print("=" * 100)
        print("í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹±: URL í¬ë¡¤ë§ + 1ë‹¨ê³„ Gemini + 2ë‹¨ê³„ ìˆœìˆ˜ ì½”ë“œ")
        print("=" * 100)
        print()

    # URL í¬ë¡¤ë§
    crawled_data = crawl_url(url)
    txt_content = crawled_data['content']
    title = crawled_data['title']
    attachments = crawled_data.get('attachments', [])

    if verbose:
        print(f"ğŸ“„ ì œëª©: {title}")
        print(f"ğŸ“ í¬ê¸°: {len(txt_content):,} bytes")
        print(f"ğŸ“ ì²¨ë¶€: {len(attachments)}ê°œ")
        print()

    # 1ë‹¨ê³„: ì•ˆê±´ ë§¤í•‘ ì¶”ì¶œ (Gemini)
    import sys
    from io import StringIO
    old_stdout = sys.stdout
    if not verbose:
        sys.stdout = StringIO()

    stage1_result, tokens = extract_agenda_mapping(txt_content, title, url, api_key, attachments, stage1_model)

    if not verbose:
        sys.stdout = old_stdout

    # 2ë‹¨ê³„: ë°œì–¸ ì¶”ì¶œ (ìˆœìˆ˜ ì½”ë“œ)
    if not verbose:
        sys.stdout = StringIO()

    # txt_contentë¥¼ full formatìœ¼ë¡œ ì¬êµ¬ì„± (í—¤ë” í¬í•¨)
    full_content = f"ì œëª©: {title}\nURL: {url}\n{'=' * 80}\n\n{txt_content}"
    chunks = parse_with_pure_code(full_content, stage1_result['agenda_mapping'])

    if not verbose:
        sys.stdout = old_stdout

    # ìµœì¢… ê²°ê³¼ (agenda_mapping í¬í•¨)
    final_result = {
        "meeting_info": stage1_result['meeting_info'],
        "agenda_mapping": stage1_result['agenda_mapping'],  # â­ ì¶”ê°€: ì²¨ë¶€ ë¬¸ì„œ ì •ë³´
        "chunks": chunks,
        "usage": {
            "stage1_model": stage1_model,
            "stage2_method": "pure_python_code",
            "stage1_tokens": tokens,
            "total_chunks": len(chunks)
        }
    }

    logger.info(f"URL ê¸°ë°˜ íŒŒì‹± ì™„ë£Œ: {len(chunks)}ê°œ ë°œì–¸, {len(attachments)}ê°œ ì²¨ë¶€")

    if verbose:
        print("=" * 100)
        print("âœ… URL ê¸°ë°˜ íŒŒì‹± ì™„ë£Œ!")
        print("=" * 100)
        print(f"ì´ ë°œì–¸ ìˆ˜: {len(chunks)}ê°œ")
        print(f"ì´ ì²¨ë¶€ ìˆ˜: {len(attachments)}ê°œ")
        print(f"Stage 1 í† í°: {tokens['input']:,} + {tokens['output']:,}")
        print(f"Stage 2 ë°©ì‹: ìˆœìˆ˜ Python ì½”ë“œ (ë¹„ìš© 0ì›)")
        print()

    return final_result


def extract_metadata_hybrid(
    txt_path: str,
    api_key: str,
    stage1_model: str = "gemini-2.5-pro",
    verbose: bool = True
) -> Dict:
    """
    í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹±: 1ë‹¨ê³„ Gemini + 2ë‹¨ê³„ ìˆœìˆ˜ ì½”ë“œ (txt íŒŒì¼ ê¸°ë°˜)

    Note: txt íŒŒì¼ì—ëŠ” ì²¨ë¶€ ë¬¸ì„œ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ attachmentsëŠ” ë¹ˆ ë°°ì—´ì…ë‹ˆë‹¤.
          ì²¨ë¶€ ë¬¸ì„œê°€ í•„ìš”í•œ ê²½ìš° extract_metadata_from_url()ì„ ì‚¬ìš©í•˜ì„¸ìš”.

    Args:
        txt_path: txt íŒŒì¼ ê²½ë¡œ
        api_key: Google API Key
        stage1_model: 1ë‹¨ê³„ ëª¨ë¸ (ê¸°ë³¸: gemini-2.5-pro)
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸: True)

    Returns:
        {
            "meeting_info": {...},
            "chunks": [...],
            "usage": {...}
        }
    """
    logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ì‹œì‘: {txt_path}")

    if verbose:
        print("=" * 100)
        print("í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹±: 1ë‹¨ê³„ Gemini + 2ë‹¨ê³„ ìˆœìˆ˜ ì½”ë“œ")
        print("=" * 100)
        print()

    # txt/md íŒŒì¼ ì½ê¸°
    with open(txt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # í—¤ë”ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (TXTì™€ MD ë‘˜ ë‹¤ ì§€ì›)
    lines_raw = content.split('\n')

    # ì œëª© ì¶”ì¶œ
    if lines_raw and lines_raw[0].startswith('# '):
        # MD í˜•ì‹: # ì œëª©
        title = lines_raw[0].replace('# ', '').strip()
    elif lines_raw and lines_raw[0].startswith('ì œëª©: '):
        # TXT í˜•ì‹: ì œëª©: xxx
        title = lines_raw[0].replace('ì œëª©: ', '').strip()
    else:
        title = ""

    # URL ì¶”ì¶œ
    url = ""
    for line in lines_raw[:10]:  # ì²« 10ì¤„ì—ì„œ URL ì°¾ê¸°
        if line.startswith('**URL**:'):
            # MD í˜•ì‹: **URL**: https://...
            url = line.replace('**URL**:', '').strip()
            break
        elif line.startswith('URL: '):
            # TXT í˜•ì‹: URL: https://...
            url = line.replace('URL: ', '').strip()
            break

    # ë³¸ë¬¸ë§Œ ì¶”ì¶œ (êµ¬ë¶„ì„  ì´í›„ ë˜ëŠ” í¬ë¡¤ë§ ì‹œê°„ ì´í›„)
    separator_index = content.find('=' * 80)
    if separator_index != -1:
        txt_content = content[separator_index + 80:].strip()
    else:
        # MD íŒŒì¼ì˜ ê²½ìš° í¬ë¡¤ë§ ì‹œê°„ ì´í›„ë¶€í„°
        crawl_time_index = content.find('**í¬ë¡¤ë§ ì‹œê°„**:')
        if crawl_time_index != -1:
            # ë‹¤ìŒ ì¤„ë¶€í„° ì‹œì‘
            remaining = content[crawl_time_index:]
            next_line = remaining.find('\n')
            if next_line != -1:
                txt_content = remaining[next_line + 1:].strip()
            else:
                txt_content = content
        else:
            txt_content = content

    if verbose:
        print(f"ğŸ“„ íŒŒì¼: {txt_path}")
        print(f"ğŸ“ ì œëª©: {title}")
        print(f"ğŸ“ í¬ê¸°: {len(txt_content):,} bytes")
        print()

    # 1ë‹¨ê³„: ì•ˆê±´ ë§¤í•‘ ì¶”ì¶œ (Gemini)
    # ì„ì‹œë¡œ print ì–µì œ
    import sys
    from io import StringIO
    old_stdout = sys.stdout
    if not verbose:
        sys.stdout = StringIO()

    # txtì—ì„œ attachmentsëŠ” ì¶”ì¶œí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
    stage1_result, tokens = extract_agenda_mapping(txt_content, title, url, api_key, [], stage1_model)

    if not verbose:
        sys.stdout = old_stdout

    # 1ë‹¨ê³„ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
    stage1_dir = Path("data/result_txt_gemini")
    stage1_dir.mkdir(parents=True, exist_ok=True)
    stage1_filename = Path(txt_path).stem + "_stage1.json"
    stage1_path = stage1_dir / stage1_filename
    with open(stage1_path, 'w', encoding='utf-8') as f:
        json.dump(stage1_result, f, ensure_ascii=False, indent=2)
    logger.info(f"1ë‹¨ê³„ ê²°ê³¼ ì €ì¥: {stage1_path}")

    # 2ë‹¨ê³„: ë°œì–¸ ì¶”ì¶œ (ìˆœìˆ˜ ì½”ë“œ)
    if not verbose:
        sys.stdout = StringIO()

    chunks = parse_with_pure_code(txt_content, stage1_result['agenda_mapping'])

    if not verbose:
        sys.stdout = old_stdout

    # ìµœì¢… ê²°ê³¼ (agenda_mapping í¬í•¨ - attachmentsëŠ” ë¹ˆ ë°°ì—´)
    final_result = {
        "meeting_info": stage1_result['meeting_info'],
        "agenda_mapping": stage1_result['agenda_mapping'],  # â­ ì¶”ê°€: ì•ˆê±´ ë§¤í•‘ (attachments ë¹ˆ ë°°ì—´)
        "chunks": chunks,
        "usage": {
            "stage1_model": stage1_model,
            "stage2_method": "pure_python_code",
            "stage1_tokens": tokens,
            "total_chunks": len(chunks)
        }
    }

    logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ì™„ë£Œ: {len(chunks)}ê°œ ë°œì–¸")

    if verbose:
        print("=" * 100)
        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ì™„ë£Œ!")
        print("=" * 100)
        print(f"ì´ ë°œì–¸ ìˆ˜: {len(chunks)}ê°œ")
        print(f"Stage 1 í† í°: {tokens['input']:,} + {tokens['output']:,}")
        print(f"Stage 2 ë°©ì‹: ìˆœìˆ˜ Python ì½”ë“œ (ë¹„ìš© 0ì›)")
        print()

    return final_result


# ============================================================================
# Gemini 2.5 Flash ì „ìš© í•¨ìˆ˜ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì ìš©)
# ============================================================================

def extract_agenda_mapping_flash(
    txt_content: str,
    title: str,
    url: str,
    api_key: str,
    attachments: List[Dict] = None,
    model: str = "gemini-2.5-flash",
    max_retries: int = 3
) -> Dict:
    """
    1ë‹¨ê³„: Gemini Flashë¡œ ì•ˆê±´ ë¼ì¸ ë§¤í•‘ ì¶”ì¶œ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)

    Args:
        txt_content: íšŒì˜ë¡ í…ìŠ¤íŠ¸
        title: íšŒì˜ë¡ ì œëª©
        url: íšŒì˜ë¡ URL
        api_key: Google API Key
        attachments: ì²¨ë¶€ ë¬¸ì„œ ëª©ë¡ [{"title": "...", "url": "..."}]
        model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: gemini-2.5-flash)
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸: 3)

    Returns:
        {
            "meeting_info": {
                "title": "...",
                "url": "...",
                "date": "YYYY.MM.DD"
            },
            "agenda_mapping": [
                {
                    "agenda_title": "ì•ˆê±´ ì œëª©",
                    "line_start": 1,
                    "line_end": 50,
                    "speakers": ["ë°œì–¸ì1", "ë°œì–¸ì2"],
                    "attachments": [{"title": "...", "url": "..."}]
                },
                ...
            ]
        }
    """
    logger.info("1ë‹¨ê³„: ì•ˆê±´ ë¼ì¸ ë§¤í•‘ ì¶”ì¶œ ì‹œì‘ (Flash)")
    print("=" * 80)
    print("1ë‹¨ê³„: ì•ˆê±´ ë¼ì¸ ë§¤í•‘ ì¶”ì¶œ (Gemini 2.5 Flash - ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)")
    print("=" * 80)
    print()

    # ì¬ì‹œë„ ë¡œì§
    for attempt in range(1, max_retries + 1):
        try:
            if attempt > 1:
                print(f"ğŸ”„ ì¬ì‹œë„ {attempt}/{max_retries}...")
                logger.info(f"ì¬ì‹œë„ {attempt}/{max_retries}")

            result, tokens = _extract_agenda_mapping_flash_once(
                txt_content, title, url, api_key, attachments, model
            )
            return result, tokens

        except json.JSONDecodeError as e:
            if attempt < max_retries:
                print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt}/{max_retries}): {e}")
                print(f"   ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt}/{max_retries}): {e}")
                continue
            else:
                print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ({max_retries}íšŒ) ë„ë‹¬, ì‹¤íŒ¨")
                logger.error(f"ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬: {e}")
                raise
        except Exception as e:
            # JSON íŒŒì‹± ì™¸ ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ì—†ì´ ë°”ë¡œ raise
            raise


def _extract_agenda_mapping_flash_once(
    txt_content: str,
    title: str,
    url: str,
    api_key: str,
    attachments: List[Dict] = None,
    model: str = "gemini-2.5-flash"
) -> Dict:
    """
    1ë‹¨ê³„: Gemini Flashë¡œ ì•ˆê±´ ë¼ì¸ ë§¤í•‘ ì¶”ì¶œ (ë‹¨ì¼ ì‹œë„)

    ì¬ì‹œë„ ë¡œì§ ì—†ì´ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
    """

    client = genai.Client(api_key=api_key)

    # ë¼ì¸ ë²ˆí˜¸ ì¶”ê°€
    lines = txt_content.split('\n')
    numbered_text = ""
    for i, line in enumerate(lines, 1):
        numbered_text += f"{i:4d} | {line}\n"

    # ì²¨ë¶€ ë¬¸ì„œ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Geminiì—ê²Œ ì „ë‹¬)
    attachments_text = ""
    if attachments:
        attachments_text = "\n\nì²¨ë¶€ ë¬¸ì„œ ëª©ë¡:\n"
        for idx, att in enumerate(attachments, 1):
            attachments_text += f"{idx}. {att['title']} (URL: {att['url']})\n"

    prompt = f"""ë‹¤ìŒì€ ì„œìš¸ì‹œì˜íšŒ íšŒì˜ë¡ì…ë‹ˆë‹¤. ì´ íšŒì˜ë¡ì„ ë¶„ì„í•˜ì—¬ ì•ˆê±´ë³„ ë¼ì¸ ë²ˆí˜¸ ë§¤í•‘ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

íšŒì˜ë¡ ì œëª©: {title}
íšŒì˜ë¡ URL: {url}
{attachments_text}

íšŒì˜ë¡ ë‚´ìš© (ë¼ì¸ ë²ˆí˜¸ í¬í•¨):
{numbered_text}

ì‘ì—…:
1. meeting_info ì¶”ì¶œ:
   - meeting_url: ìœ„ì— ì œê³µëœ "íšŒì˜ë¡ URL"ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
   - date: ì œëª©ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (YYYY.MM.DD í˜•ì‹)

2. agenda_mapping ì¶”ì¶œ:

**ì•ˆê±´ ì‹ë³„ ê·œì¹™:**

1ë‹¨ê³„: "ì‹¬ì‚¬ëœì•ˆê±´" ë˜ëŠ” "ì˜ì‚¬ì¼ì •" ì„¹ì…˜ì—ì„œ ì•ˆê±´ ëª©ë¡ ì¶”ì¶œ
   - "1. 2. 3. ..." í˜•íƒœì˜ ì•ˆê±´ ëª©ë¡ì„ ëª¨ë‘ ì°¾ìœ¼ì„¸ìš”
   - agenda_titleì€ ë²ˆí˜¸ë¥¼ ì œì™¸í•œ ìˆœìˆ˜ ì•ˆê±´ëª…ë§Œ ì‚¬ìš©
   - ì˜ˆ: "1. ê¸°íšì¡°ì •ì‹¤ í˜„ì•ˆ ì—…ë¬´ë³´ê³ " â†’ "ê¸°íšì¡°ì •ì‹¤ í˜„ì•ˆ ì—…ë¬´ë³´ê³ "

2ë‹¨ê³„: ê° ì•ˆê±´ì˜ ë…¼ì˜ êµ¬ê°„ ì§€ì • (ì¼ê´„ìƒì • ì•ˆê±´ ì²˜ë¦¬ ê·œì¹™)
   - "---" êµ¬ë¶„ì„ , "â—‹ìœ„ì›ì¥" ë˜ëŠ” "â—‹ì˜ì¥" ë°œì–¸, ì•ˆê±´ëª… ì–¸ê¸‰ì„ ì°¸ê³ í•˜ì—¬ line_start, line_end ì§€ì •

   **ë³¸íšŒì˜ ì¼ê´„ìƒì • ì•ˆê±´ ì²˜ë¦¬:**
   - íšŒì˜ ì œëª©ì— "ë³¸íšŒì˜"ê°€ í¬í•¨ë˜ê³  ì—¬ëŸ¬ ì•ˆê±´ì´ ì¼ê´„ ìƒì •ëœ ê²½ìš°
   - ê° ì•ˆê±´ë³„ë¡œ "ì˜ì‚¬ì¼ì • ì œXí•­ì€ ê°€ê²°ë˜ì—ˆìŒ" ë˜ëŠ” "ì˜ì‚¬ì¼ì • ì œXí•­ì„ í‘œê²°í•˜ê² ìŠµë‹ˆë‹¤" í˜•íƒœì˜ ê°œë³„ í‘œê²°ì´ ìˆëŠ”ì§€ í™•ì¸
   - ê°œë³„ í‘œê²°ì´ ìˆìœ¼ë©´ â†’ **ê° ì•ˆê±´ì„ ë°˜ë“œì‹œ ë¶„ë¦¬**
     * ê° ì•ˆê±´ì˜ line_start: í•´ë‹¹ ì•ˆê±´ í‘œê²° ì‹œì‘ ë¼ì¸ (ì˜ˆ: "ì˜ì‚¬ì¼ì • ì œ24í•­ ... í‘œê²°í•˜ê² ìŠµë‹ˆë‹¤")
     * ê° ì•ˆê±´ì˜ line_end: í•´ë‹¹ ì•ˆê±´ í‘œê²° ì¢…ë£Œ ë¼ì¸ (ì˜ˆ: "ê°€ê²°ë˜ì—ˆìŒì„ ì„ í¬í•©ë‹ˆë‹¤" ë˜ëŠ” ë‹¤ìŒ ì•ˆê±´ ì‹œì‘ ì§ì „)
     * ê° ì•ˆê±´ì˜ status: ê°œë³„ í‘œê²° ê²°ê³¼ ë°˜ì˜

   **ìœ„ì›íšŒ ì¼ê´„ìƒì • ì•ˆê±´ ì²˜ë¦¬ (ë³¸íšŒì˜ ì™¸):**
   - ì—¬ëŸ¬ ì•ˆê±´ì´ "ì¼ê´„ ìƒì •" ë˜ëŠ” "ì¼ê´„í•´ì„œ ìƒì •"ëœ ê²½ìš° ë³¸ë¬¸ì„ ë¶„ì„í•˜ì—¬ íŒë‹¨:

   ì¡°ê±´ A (í†µí•© ì²˜ë¦¬): ë‹¤ìŒ ì¡°ê±´ì„ **ëª¨ë‘** ë§Œì¡±í•˜ë©´ í†µí•©
     âœ“ ì¼ê´„ ì œì•ˆì„¤ëª… (ê° ì•ˆê±´ë³„ ê°œë³„ ì„¤ëª… ì—†ìŒ)
     âœ“ ì¼ê´„ ê²€í† ë³´ê³  (ê° ì•ˆê±´ë³„ ê°œë³„ ê²€í†  ì—†ìŒ)
     âœ“ ì¼ê´„ ì§ˆì˜ì‘ë‹µ (ì•ˆê±´ êµ¬ë¶„ ì—†ì´ ì „ì²´ì— ëŒ€í•œ ì§ˆì˜)
     âœ“ ì¼ê´„ í‘œê²° (ê° ì•ˆê±´ë³„ ê°œë³„ í‘œê²° ì—†ìŒ)
     â†’ agenda_titleì„ ì‰¼í‘œë¡œ ì—°ê²°: "ì•ˆê±´1,ì•ˆê±´2,ì•ˆê±´3,ì•ˆê±´4"
     â†’ line_start/line_endëŠ” ì „ì²´ ë…¼ì˜ êµ¬ê°„ í•˜ë‚˜ë¡œ ì§€ì •
     â†’ statusëŠ” ì „ì²´ ì•ˆê±´ì˜ ê³µí†µ ì²˜ë¦¬ ê²°ê³¼

   ì¡°ê±´ B (ë¶„ë¦¬ ì²˜ë¦¬): ë‹¤ìŒ ì¡°ê±´ ì¤‘ **í•˜ë‚˜ë¼ë„** í•´ë‹¹í•˜ë©´ ë¶„ë¦¬
     âœ“ ê° ì•ˆê±´ë³„ë¡œ ê°œë³„ ì œì•ˆì„¤ëª…ì´ êµ¬ë¶„ë˜ì–´ ìˆìŒ
     âœ“ ê° ì•ˆê±´ë³„ë¡œ ê°œë³„ ê²€í† ë³´ê³ ê°€ êµ¬ë¶„ë˜ì–´ ìˆìŒ
     âœ“ ê° ì•ˆê±´ì— ëŒ€í•œ ê°œë³„ ì§ˆì˜ì‘ë‹µì´ "---" êµ¬ë¶„ì„ ìœ¼ë¡œ ë‚˜ë‰˜ì–´ ìˆìŒ
     âœ“ ê° ì•ˆê±´ë³„ë¡œ ê°œë³„ í‘œê²°ì´ ì§„í–‰ë¨
     â†’ ê° ì•ˆê±´ì„ ë³„ë„ agendaë¡œ ë¶„ë¦¬
     â†’ ê°ê°ì˜ line_start/line_end ê°œë³„ ì§€ì •
     â†’ ê°ê°ì˜ status ê°œë³„ ê¸°ë¡

   **íŒë‹¨ ì˜ˆì‹œ:**
   ì˜ˆì‹œ 1 (í†µí•©): "ì˜ì‚¬ì¼ì • ì œ4í•­~ì œ8í•­ì„ ì¼ê´„ ìƒì •" â†’ ìœ„ì›ì¥ì´ 5ê°œ ì•ˆê±´ì„ í•œë²ˆì— ì„¤ëª… â†’ ì „ë¬¸ìœ„ì›ì´ ì¼ê´„ ê²€í† ë³´ê³  â†’ ì§ˆì˜ì‘ë‹µ â†’ "ì œ4í•­ë¶€í„° ì œ8í•­ê¹Œì§€ ì›ì•ˆëŒ€ë¡œ ì˜ê²°" (í•œë²ˆì— í‘œê²°)
   â†’ agenda_title: "ì•ˆê±´4,ì•ˆê±´5,ì•ˆê±´6,ì•ˆê±´7,ì•ˆê±´8"

   ì˜ˆì‹œ 2 (ë¶„ë¦¬): "ì˜ì‚¬ì¼ì • ì œ24í•­~ì œ33í•­ì„ ì¼ê´„ ìƒì •" â†’ ì‹¬ì‚¬ë³´ê³ ëŠ” ìƒëµ â†’ í•˜ì§€ë§Œ "ì œ24í•­ì„ í‘œê²°í•˜ê² ìŠµë‹ˆë‹¤" â†’ "ì œ25í•­ì„ í‘œê²°í•˜ê² ìŠµë‹ˆë‹¤" â†’ ... (ê°ê° ê°œë³„ íˆ¬í‘œ)
   â†’ 10ê°œì˜ ê°œë³„ agendaë¡œ ë¶„ë¦¬

**íšŒì˜ë¡ êµ¬ì¡° ì´í•´:**
- íšŒì˜ë¡ì€ "---" êµ¬ë¶„ì„ ìœ¼ë¡œ ì„¹ì…˜ì´ ë‚˜ë‰˜ì–´ì ¸ ìˆìŒ
- ê° "---" êµ¬ë¶„ì„  ì‚¬ì´ì— ì‹¤ì œ ë°œì–¸("â—‹ìœ„ì›ì¥", "â—‹ìœ„ì›" ë“±)ì´ í¬í•¨ëœ êµ¬ê°„ì€ í•˜ë‚˜ì˜ ì•ˆê±´ìœ¼ë¡œ ì¶”ì¶œ
- ì²¨ë¶€ ë¬¸ì„œ(download_url)ëŠ” í•´ë‹¹ ì•ˆê±´ ë…¼ì˜ ì§í›„ì— "(ì°¸ê³ )" í˜•íƒœë¡œ ì œê³µë˜ë©°, ë°”ë¡œ ì• ì•ˆê±´ì˜ attachmentsì— ë§¤í•‘
- line_startëŠ” ì‹¤ì œ ë°œì–¸ì´ ì‹œì‘ë˜ëŠ” ì²« ë¼ì¸ (ì˜ˆ: â—‹ìœ„ì›ì¥ ê¹€í˜œì˜  ì˜ì‚¬ì¼ì • ì œ1í•­...), line_endëŠ” ë°œì–¸ì´ ëë‚˜ëŠ” ë§ˆì§€ë§‰ ë¼ì¸ ("---" êµ¬ë¶„ì„ ì´ë‚˜ "(ì°¸ê³ )" ì„¹ì…˜ ì§ì „)

**ì•ˆê±´ ì™¸ ì„¹ì…˜:**
- ì•ˆê±´ ëª©ë¡ì— ì—†ì–´ë„ ì‹¤ì œ íšŒì˜ ë‚´ìš©(ê°œì˜, ì§ˆì˜ì‘ë‹µ, 5ë¶„ììœ ë°œì–¸, ì‚°íšŒ ë“±)ì€ ëª¨ë‘ í¬í•¨
- ì„¹ì…˜ ì„±ê²©ì— ë§ëŠ” ì ì ˆí•œ ì œëª© ì‚¬ìš©

**ì²¨ë¶€ ë¬¸ì„œ ë§¤ì¹­:**
- íšŒì˜ë¡ ë³¸ë¬¸ì—ì„œ ë§ˆí¬ë‹¤ìš´ ë§í¬ í˜•ì‹ì˜ ì²¨ë¶€ ë¬¸ì„œë¥¼ ì°¾ì•„ì„œ ë§¤ì¹­
  * í˜•ì‹: [ë¬¸ì„œëª…](https://ms.smc.seoul.kr/record/appendixDownload.do?key=...)
  * (ì°¸ê³ ) ì„¹ì…˜ì˜ ë§í¬ëŠ” ë°”ë¡œ ì§ì „ ì•ˆê±´ì— ì†í•¨
- ê° ì•ˆê±´ì— í•´ë‹¹í•˜ëŠ” ì²¨ë¶€ ë¬¸ì„œë¥¼ attachments í•„ë“œì— ë°°ì—´ë¡œ ì¶”ê°€
- ì•ˆê±´ê³¼ ê´€ë ¨ ì—†ëŠ” ì²¨ë¶€ ë¬¸ì„œëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
- ì²¨ë¶€ ë¬¸ì„œê°€ ì—†ëŠ” ì•ˆê±´ì€ attachmentsë¥¼ ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •
- **ì¤‘ìš”**: URLì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ê³ , URLì´ ì—†ìœ¼ë©´ nullë¡œ ì„¤ì •í•˜ì§€ ë§ê³  í•´ë‹¹ í•­ëª©ì„ ì œì™¸

**ì¤‘ìš”:**
- ëª¨ë“  ì•ˆê±´ì„ ë¹ ì§ì—†ì´ í¬í•¨ (ë‹¨ í•˜ë‚˜ë„ ëˆ„ë½ ê¸ˆì§€)
- "(íšŒì˜ë¡ ëì— ì‹¤ìŒ)" ë˜ëŠ” "(ì°¸ê³ )" ì„¹ì…˜ì€ ì œì™¸
- speakers: í•´ë‹¹ êµ¬ê°„ì˜ ë°œì–¸ì ëª©ë¡ (â—‹ ë‹¤ìŒ ì´ë¦„, ë°œì–¸ ìˆœì„œëŒ€ë¡œ)

**ì•ˆê±´ íƒ€ì… ë¶„ë¥˜:**
ê° ì•ˆê±´ì— agenda_type í•„ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜:
- "legislation": ì¡°ë¡€ì•ˆ, ê·œì¹™ì•ˆ ë“± ì…ë²• ì•ˆê±´
- "report": ì—…ë¬´ë³´ê³ , í˜„ì•ˆë³´ê³  ë“± ë³´ê³  ì•ˆê±´
- "budget": ì˜ˆì‚°ì•ˆ, ê²°ì‚° ê´€ë ¨ ì•ˆê±´
- "consent": ë™ì˜ì•ˆ, ìŠ¹ì¸ì•ˆ, ì˜ê²¬ì²­ì·¨ ì•ˆê±´
- "procedural": ê°œì˜, ê°œíšŒ, ííšŒ, ì‚°íšŒ ë“± ì ˆì°¨ì  ì•ˆê±´
- "personnel": ìœ„ì›ì¥ ì„ ê±°, ìœ„ì› ì„ ì„ ë“± ì¸ì‚¬ ì•ˆê±´
- "discussion": ì§ˆì˜ì‘ë‹µ, 5ë¶„ììœ ë°œì–¸ ë“± í† ë¡ 
- "other": ê¸°íƒ€

**ì•ˆê±´ ìƒíƒœ ì¶”ì¶œ:**
ê° ì•ˆê±´ì˜ ì²˜ë¦¬ ìƒíƒœë¥¼ íŒŒì•…í•˜ì—¬ status í•„ë“œì— ê¸°ë¡:
- íšŒì˜ë¡ì—ì„œ í•´ë‹¹ ì•ˆê±´ì´ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ ì°¾ì•„ì„œ ê¸°ë¡
- ê°€ëŠ¥í•œ ìƒíƒœ ê°’:
  * "ì›ì•ˆê°€ê²°": "ì›ì•ˆê°€ê²°", "ê°€ê²°ë˜ì—ˆìŒ", "ì˜ê²°ë˜ì—ˆìŒ" ë“±
  * "ìˆ˜ì •ê°€ê²°": "ìˆ˜ì •ê°€ê²°", "ì¼ë¶€ ìˆ˜ì •í•˜ì—¬ ê°€ê²°" ë“±
  * "ë¶€ê²°": "ë¶€ê²°ë˜ì—ˆìŒ"
  * "ë³¸íšŒì˜ ìƒì •": "ë³¸íšŒì˜ì— ë¶€ì˜", "ë³¸íšŒì˜ ìƒì •" ë“±
  * "ìœ„ì›íšŒ ì‹¬ì‚¬ì¤‘": "ìœ„ì›íšŒì— ìƒì •", "ì‹¬ì‚¬ ì¤‘" ë“±
  * "ì ‘ìˆ˜": ìƒíƒœê°€ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’
- íšŒì˜ë¡ì— ëª…ì‹œëœ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì˜ˆ: "ì›ì•ˆê°€ê²°ë˜ì—ˆìŒì„ ì„ í¬í•©ë‹ˆë‹¤" â†’ "ì›ì•ˆê°€ê²°")
- ìƒíƒœê°€ ë¶ˆëª…í™•í•˜ë©´ "ì ‘ìˆ˜" ì‚¬ìš©

JSON ì¶œë ¥ í˜•ì‹:
{{{{
  "meeting_info": {{{{
    "title": "{title}",
    "meeting_url": "{url}",
    "date": "YYYY.MM.DD"
  }}}},
  "agenda_mapping": [
    {{{{
      "agenda_title": "ì•ˆê±´ëª…",
      "agenda_type": "legislation",
      "status": "ì›ì•ˆê°€ê²°",
      "line_start": 1,
      "line_end": 50,
      "speakers": ["ë°œì–¸ì1", "ë°œì–¸ì2"],
      "attachments": [
        {{{{"title": "ë¬¸ì„œëª…", "download_url": "ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ URL"}}}}
      ]
    }}}}
  ]
}}}}

ê·œì¹™:
- ìˆœìˆ˜ JSONë§Œ ì¶œë ¥
- agenda_mappingì€ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë°°ì—´
- line_start, line_endëŠ” ì‹¤ì œ ë¼ì¸ ë²ˆí˜¸ ì‚¬ìš©
- attachmentsëŠ” í•´ë‹¹ ì•ˆê±´ì— ì†í•œ ì²¨ë¶€ ë¬¸ì„œë§Œ í¬í•¨ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)
- agenda_typeì€ ë°˜ë“œì‹œ ìœ„ 8ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜
- statusëŠ” íšŒì˜ë¡ì—ì„œ ì¶”ì¶œí•œ ì‹¤ì œ ì²˜ë¦¬ ìƒíƒœ (ì—†ìœ¼ë©´ "ì ‘ìˆ˜")
"""

    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.1,
                response_mime_type="application/json",
            )
        )
    except Exception as e:
        error_msg = f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}"
        print(f"âŒ {error_msg}")
        logger.error(error_msg)
        import traceback
        traceback.print_exc()
        raise

    # finish_reason í™•ì¸ (ë””ë²„ê¹…)
    if response.candidates and len(response.candidates) > 0:
        finish_reason = getattr(response.candidates[0], 'finish_reason', None)
        if finish_reason:
            print(f"ğŸ” Finish Reason: {finish_reason}")
            if finish_reason not in ['STOP', 1]:  # STOP = ì •ìƒ ì™„ë£Œ
                print(f"âš ï¸  ì‘ë‹µì´ ë¹„ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë¨: {finish_reason}")

    response_text = None
    try:
        response_text = response.text
    except Exception as e:
        print(f"âŒ response.text ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        logger.error(f"response.text ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    if not response_text:
        print("âš ï¸  response.textê°€ ë¹„ì–´ìˆìŒ, candidatesì—ì„œ ì¶”ì¶œ ì‹œë„...")
        if response.candidates and len(response.candidates) > 0:
            candidate = response.candidates[0]
            if hasattr(candidate, 'content') and candidate.content:
                if hasattr(candidate.content, 'parts') and candidate.content.parts:
                    if len(candidate.content.parts) > 0:
                        part = candidate.content.parts[0]
                        if hasattr(part, 'text'):
                            response_text = part.text
                            print(f"âœ… candidatesì—ì„œ ì¶”ì¶œ ì„±ê³µ (ê¸¸ì´: {len(response_text)})")

    if not response_text:
        error_msg = "Gemini ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
        print(f"âŒ {error_msg}")
        print(f"   Response: {response}")
        if hasattr(response, 'prompt_feedback'):
            print(f"   Prompt Feedback: {response.prompt_feedback}")
        logger.error(error_msg)
        raise Exception(error_msg)

    try:
        result = json.loads(response_text)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì—ëŸ¬: {e}")
        print(f"   Response text (ì²˜ìŒ 500ì): {response_text[:500]}")

        # ì „ì²´ ì‘ë‹µì„ íŒŒì¼ë¡œ ì €ì¥
        error_log_dir = Path("logs/gemini_errors")
        error_log_dir.mkdir(parents=True, exist_ok=True)
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        error_file = error_log_dir / f"json_error_{timestamp}.txt"
        with open(error_file, 'w', encoding='utf-8') as f:
            f.write(f"=== JSON íŒŒì‹± ì—ëŸ¬ ===\n")
            f.write(f"íšŒì˜ë¡: {title}\n")
            f.write(f"URL: {url}\n")
            f.write(f"ì—ëŸ¬: {e}\n")
            f.write(f"ëª¨ë¸: {model}\n")
            f.write(f"\n=== Gemini ì‘ë‹µ ì „ë¬¸ ===\n")
            f.write(response_text)
        print(f"   ì „ì²´ ì‘ë‹µ ì €ì¥: {error_file}")

        logger.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
        raise

    # í† í° ì •ë³´
    tokens = {"input": 0, "output": 0}
    if hasattr(response, 'usage_metadata'):
        tokens["input"] = getattr(response.usage_metadata, 'prompt_token_count', 0)
        tokens["output"] = getattr(response.usage_metadata, 'candidates_token_count', 0)

    logger.info(f"1ë‹¨ê³„ ì™„ë£Œ (Flash): {len(result['agenda_mapping'])}ê°œ ì•ˆê±´, í† í°={tokens['input']}+{tokens['output']}")
    print(f"âœ… ì•ˆê±´ ë§¤í•‘ ì¶”ì¶œ ì™„ë£Œ (Flash): {len(result['agenda_mapping'])}ê°œ")
    print(f"ğŸ“Š í† í°: input={tokens['input']:,}, output={tokens['output']:,}")
    print()

    return result, tokens


def extract_metadata_hybrid_flash(
    txt_path: str,
    api_key: str,
    verbose: bool = True
) -> Dict:
    """
    í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± (Flash ì „ìš©): 1ë‹¨ê³„ Gemini Flash + 2ë‹¨ê³„ ìˆœìˆ˜ ì½”ë“œ (txt/md íŒŒì¼ ê¸°ë°˜)

    ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ gemini-2.5-flashì˜ íŒŒì‹± ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

    Note: txt íŒŒì¼ì—ëŠ” ì²¨ë¶€ ë¬¸ì„œ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ attachmentsëŠ” ë¹ˆ ë°°ì—´ì…ë‹ˆë‹¤.
          ì²¨ë¶€ ë¬¸ì„œê°€ í•„ìš”í•œ ê²½ìš° extract_metadata_from_url()ì„ ì‚¬ìš©í•˜ì„¸ìš”.

    Args:
        txt_path: txt/md íŒŒì¼ ê²½ë¡œ
        api_key: Google API Key
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸: True)

    Returns:
        {
            "meeting_info": {...},
            "agenda_mapping": [...],
            "chunks": [...],
            "usage": {...}
        }
    """
    logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ì‹œì‘ (Flash): {txt_path}")

    if verbose:
        print("=" * 100)
        print("í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± (Flash): 1ë‹¨ê³„ Gemini Flash + 2ë‹¨ê³„ ìˆœìˆ˜ ì½”ë“œ")
        print("=" * 100)
        print()

    # txt/md íŒŒì¼ ì½ê¸°
    with open(txt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # í—¤ë”ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (TXTì™€ MD ë‘˜ ë‹¤ ì§€ì›)
    lines_raw = content.split('\n')

    # ì œëª© ì¶”ì¶œ
    if lines_raw and lines_raw[0].startswith('# '):
        # MD í˜•ì‹: # ì œëª©
        title = lines_raw[0].replace('# ', '').strip()
    elif lines_raw and lines_raw[0].startswith('ì œëª©: '):
        # TXT í˜•ì‹: ì œëª©: xxx
        title = lines_raw[0].replace('ì œëª©: ', '').strip()
    else:
        title = ""

    # URL ì¶”ì¶œ
    url = ""
    for line in lines_raw[:10]:  # ì²« 10ì¤„ì—ì„œ URL ì°¾ê¸°
        if line.startswith('**URL**:'):
            # MD í˜•ì‹: **URL**: https://...
            url = line.replace('**URL**:', '').strip()
            break
        elif line.startswith('URL: '):
            # TXT í˜•ì‹: URL: https://...
            url = line.replace('URL: ', '').strip()
            break

    # ë³¸ë¬¸ë§Œ ì¶”ì¶œ (êµ¬ë¶„ì„  ì´í›„ ë˜ëŠ” í¬ë¡¤ë§ ì‹œê°„ ì´í›„)
    separator_index = content.find('=' * 80)
    if separator_index != -1:
        txt_content = content[separator_index + 80:].strip()
    else:
        # MD íŒŒì¼ì˜ ê²½ìš° í¬ë¡¤ë§ ì‹œê°„ ì´í›„ë¶€í„°
        crawl_time_index = content.find('**í¬ë¡¤ë§ ì‹œê°„**:')
        if crawl_time_index != -1:
            # ë‹¤ìŒ ì¤„ë¶€í„° ì‹œì‘
            remaining = content[crawl_time_index:]
            next_line = remaining.find('\n')
            if next_line != -1:
                txt_content = remaining[next_line + 1:].strip()
            else:
                txt_content = content
        else:
            txt_content = content

    if verbose:
        print(f"ğŸ“„ íŒŒì¼: {txt_path}")
        print(f"ğŸ“ ì œëª©: {title}")
        print(f"ğŸ“ í¬ê¸°: {len(txt_content):,} bytes")
        print()

    # 1ë‹¨ê³„: ì•ˆê±´ ë§¤í•‘ ì¶”ì¶œ (Gemini Flash - ê°œì„ ëœ í”„ë¡¬í”„íŠ¸) with ì¬ì‹œë„
    import sys
    from io import StringIO
    old_stdout = sys.stdout

    max_retries = 3
    stage1_result = None
    tokens = {"input": 0, "output": 0}

    for attempt in range(max_retries + 1):
        if not verbose:
            sys.stdout = StringIO()

        # txtì—ì„œ attachmentsëŠ” ì¶”ì¶œí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
        stage1_result, tokens = extract_agenda_mapping_flash(txt_content, title, url, api_key, [])

        if not verbose:
            sys.stdout = old_stdout

        # ì¤‘ë³µ line range ê²€ì¦
        has_overlap = False
        overlap_details = []
        agendas = stage1_result.get('agenda_mapping', [])

        for i in range(len(agendas)):
            for j in range(i + 1, len(agendas)):
                agenda1 = agendas[i]
                agenda2 = agendas[j]

                start1 = agenda1.get('line_start', 0)
                end1 = agenda1.get('line_end', 0)
                start2 = agenda2.get('line_start', 0)
                end2 = agenda2.get('line_end', 0)

                # ê²¹ì¹¨ ê³„ì‚° (5ì¤„ ì´ìƒ ê²¹ì¹˜ë©´ ë¬¸ì œ)
                overlap_start = max(start1, start2)
                overlap_end = min(end1, end2)
                overlap = max(0, overlap_end - overlap_start)

                if overlap > 5:
                    has_overlap = True
                    overlap_details.append({
                        'agenda1_title': agenda1.get('agenda_title', '(ì œëª©ì—†ìŒ)')[:40],
                        'range1': f"{start1}-{end1}",
                        'agenda2_title': agenda2.get('agenda_title', '(ì œëª©ì—†ìŒ)')[:40],
                        'range2': f"{start2}-{end2}",
                        'overlap': overlap
                    })

        if not has_overlap:
            if verbose and attempt > 0:
                print(f"âœ… ì¬ì‹œë„ ì„±ê³µ (ì‹œë„ {attempt + 1}): ì¤‘ë³µ line range í•´ê²°ë¨")
            break
        else:
            if attempt < max_retries:
                if verbose:
                    print(f"âš ï¸  ì‹œë„ {attempt + 1}: ì¤‘ë³µ line range ë°œê²¬ ({len(overlap_details)}ê°œ)")
                    for detail in overlap_details[:3]:
                        print(f"   - {detail['agenda1_title']} ({detail['range1']}) â†” {detail['agenda2_title']} ({detail['range2']}) | ê²¹ì¹¨: {detail['overlap']}ì¤„")
                    print(f"ğŸ”„ Stage 1 ì¬ì‹œë„ ì¤‘...")
                logger.warning(f"ì¤‘ë³µ line range ë°œê²¬, ì¬ì‹œë„ {attempt + 1}/{max_retries}")
            else:
                if verbose:
                    print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: ì¤‘ë³µ line rangeê°€ ì—¬ì „íˆ ì¡´ì¬í•¨ ({len(overlap_details)}ê°œ)")
                    print(f"   ê³„ì† ì§„í–‰í•˜ì§€ë§Œ ê²°ê³¼ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                logger.error(f"ì¤‘ë³µ line range í•´ê²° ì‹¤íŒ¨ (ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼)")

    if not verbose:
        sys.stdout = old_stdout

    # 1ë‹¨ê³„ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
    stage1_dir = Path("data/result_txt_gemini_flash")
    stage1_dir.mkdir(parents=True, exist_ok=True)
    stage1_filename = Path(txt_path).stem + "_stage1_flash.json"
    stage1_path = stage1_dir / stage1_filename
    with open(stage1_path, 'w', encoding='utf-8') as f:
        json.dump(stage1_result, f, ensure_ascii=False, indent=2)
    logger.info(f"1ë‹¨ê³„ ê²°ê³¼ ì €ì¥ (Flash): {stage1_path}")

    # 2ë‹¨ê³„: ë°œì–¸ ì¶”ì¶œ (ìˆœìˆ˜ ì½”ë“œ)
    if not verbose:
        sys.stdout = StringIO()

    chunks = parse_with_pure_code(txt_content, stage1_result['agenda_mapping'])

    if not verbose:
        sys.stdout = old_stdout

    # ìµœì¢… ê²°ê³¼ (agenda_mapping í¬í•¨ - attachmentsëŠ” ë¹ˆ ë°°ì—´)
    final_result = {
        "meeting_info": stage1_result['meeting_info'],
        "agenda_mapping": stage1_result['agenda_mapping'],  # â­ ì¶”ê°€: ì•ˆê±´ ë§¤í•‘ (Flash)
        "chunks": chunks,
        "usage": {
            "stage1_model": "gemini-2.5-flash",
            "stage2_method": "pure_python_code",
            "stage1_tokens": tokens,
            "total_chunks": len(chunks)
        }
    }

    logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ì™„ë£Œ (Flash): {len(chunks)}ê°œ ë°œì–¸")

    if verbose:
        print("=" * 100)
        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ì™„ë£Œ (Flash)!")
        print("=" * 100)
        print(f"ì´ ë°œì–¸ ìˆ˜: {len(chunks)}ê°œ")
        print(f"Stage 1 í† í°: {tokens['input']:,} + {tokens['output']:,}")
        print(f"Stage 2 ë°©ì‹: ìˆœìˆ˜ Python ì½”ë“œ (ë¹„ìš© 0ì›)")
        print()

    return final_result


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    from dotenv import load_dotenv
    import random
    load_dotenv()

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # result í´ë”ì˜ ëª¨ë“  txt íŒŒì¼ ì°¾ê¸°
    result_dir = Path("result")
    all_txt_files = list(result_dir.glob("*/meeting_*.txt"))

    if len(all_txt_files) == 0:
        print("âŒ result í´ë”ì— txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ëœë¤ìœ¼ë¡œ 3ê°œ ì„ íƒ
    random.seed()  # ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ê³¼
    selected_files = random.sample(all_txt_files, min(3, len(all_txt_files)))

    print("=" * 100)
    print("ğŸ² ëœë¤ìœ¼ë¡œ ì„ íƒëœ íŒŒì¼ 3ê°œ (ìˆ˜ì •ëœ íŒŒì„œ í…ŒìŠ¤íŠ¸)")
    print("=" * 100)
    for i, file in enumerate(selected_files, 1):
        print(f"{i}. {file.parent.name}")
    print()

    success_count = 0
    fail_count = 0

    for idx, txt_path in enumerate(selected_files, 1):
        print("=" * 100)
        print(f"[{idx}/3] {txt_path.parent.name}")
        print("=" * 100)
        print()

        try:
            result = extract_metadata_hybrid(
                txt_path=str(txt_path),
                api_key=api_key,
                stage1_model="gemini-2.5-pro",
                verbose=True
            )

            # ì œëª©ì—ì„œ ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
            title = result['meeting_info']['title']
            safe_title = title.replace('/', '_').replace('\\', '_').replace(':', '_').replace('*', '_').replace('?', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_')

            # ê²°ê³¼ ì €ì¥ (test_{title}.json)
            output_path = Path("test_results") / f"test_{safe_title}.json"
            output_path.parent.mkdir(exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
            print()

            # í†µê³„
            speakers = set(chunk['speaker'] for chunk in result['chunks'])
            agendas = set(chunk['agenda'] for chunk in result['chunks'])

            print("ğŸ“Š í†µê³„")
            print(f"  - ì´ ë°œì–¸ ìˆ˜: {len(result['chunks'])}ê°œ")
            print(f"  - ë°œì–¸ì: {len(speakers)}ëª…")
            print(f"  - ì•ˆê±´: {len(agendas)}ê°œ")
            print()

            success_count += 1

        except Exception as e:
            logger.error(f"íŒŒì‹± ì‹¤íŒ¨: {txt_path} - {e}")
            print(f"âŒ ì‹¤íŒ¨: {e}")
            print()
            fail_count += 1

    # ìµœì¢… ê²°ê³¼
    print("=" * 100)
    print("ğŸ“Š ìµœì¢… ê²°ê³¼")
    print("=" * 100)
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
    print()


if __name__ == "__main__":
    main()
